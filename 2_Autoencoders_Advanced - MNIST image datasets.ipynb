{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1c9360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tf_ds\n",
    "import tensorflow_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f822ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02adcede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_image(image,label):\n",
    "    image = tf.cast(image,dtype=tf.float32)\n",
    "    image = image/255.0\n",
    "    image = tf.reshape(image,shape=(28*28*1,))\n",
    "    return image, image\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4440005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Train and Test datasets from Tensorflow datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16c0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "SHUFFLE_BUFFER_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b1efb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "})> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "})> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "})> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <function map_image at 0x000002E2D00B3D08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function map_image at 0x000002E2D00B3D08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function map_image at 0x000002E2D00B3D08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "train_datasets = tf_ds.load(\"mnist\",as_supervised=True,split='train')\n",
    "train_datasets = train_datasets.map(map_image)\n",
    "train_datasets = train_datasets.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e93315cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "})> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "})> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "})> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "test_dataset = tf_ds.load(\"mnist\",as_supervised=True,split='test')\n",
    "test_dataset = test_dataset.map(map_image)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b2b62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f8bc015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_autoencoder(inputs):\n",
    "    # Build Encoder-Decoder using Dense Model \n",
    "    encoder = keras.layers.Dense(units=32, activation='relu')(inputs)\n",
    "    decoder = keras.layers.Dense(units=28*28*1,activation='sigmoid')(encoder)\n",
    "    return encoder, decoder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11e2791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the input shape :\n",
    "input_ = tf.keras.Input(shape=(28*28*1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07f6a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get encoder & Decoder output :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d47123af",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output, decoder_output = simple_autoencoder(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cfea50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = tf.keras.Model(inputs=input_,outputs=encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55c84865",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_model = tf.keras.Model(inputs=input_,outputs=decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39c0e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98cb9507",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_model.compile(optimizer=tf.keras.optimizers.Adam(),loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7582bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the encoder model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08c9674a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1000 steps\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1825\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1120\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0990\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0953\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0943\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0938\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0935\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0933\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0933\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0932\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0931\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0931\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0930\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0930\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0929\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0929\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0928\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0928\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0928\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0928\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0927\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0927\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0926\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0927\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0926\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0926\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0926\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0925\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0925\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0925\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0924\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0924\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0924\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0924\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0924\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0923 0s - \n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0923\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0923\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0923\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0923\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0922\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0922\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0922\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0922\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0922\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0922\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0921\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0921\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0921\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0922\n"
     ]
    }
   ],
   "source": [
    "train_steps = 1000\n",
    "simple_auto_history = autoencoder_model.fit(train_datasets,steps_per_epoch=train_steps,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fbdb5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.18248987193403393,\n",
       "  0.11197136535592053,\n",
       "  0.09897871420585018,\n",
       "  0.09531158739966474,\n",
       "  0.09427695806926045,\n",
       "  0.09376523009743197,\n",
       "  0.09353549985318496,\n",
       "  0.09334081692459406,\n",
       "  0.09326536697393778,\n",
       "  0.09317054352413243,\n",
       "  0.0930849613119597,\n",
       "  0.0930778491140724,\n",
       "  0.09301137297287054,\n",
       "  0.09298653550457214,\n",
       "  0.09291509049886343,\n",
       "  0.09287947305022164,\n",
       "  0.09283233477196853,\n",
       "  0.0927949514167347,\n",
       "  0.0927746229194265,\n",
       "  0.09279241710863989,\n",
       "  0.09272642337855487,\n",
       "  0.09271116967146667,\n",
       "  0.09262550754571873,\n",
       "  0.0926611544513118,\n",
       "  0.09258911193997459,\n",
       "  0.09257147444776441,\n",
       "  0.09256474748850167,\n",
       "  0.0925427976773941,\n",
       "  0.09251540426673623,\n",
       "  0.09248340166192046,\n",
       "  0.09244457554572637,\n",
       "  0.09240099917789768,\n",
       "  0.09238948976027482,\n",
       "  0.09238358925452168,\n",
       "  0.09238780625332231,\n",
       "  0.09234401741889252,\n",
       "  0.09233181286843614,\n",
       "  0.09229348735240271,\n",
       "  0.09229167734178202,\n",
       "  0.09226085738339025,\n",
       "  0.09221387971910075,\n",
       "  0.09223485333083749,\n",
       "  0.09224468857057397,\n",
       "  0.09221531861667158,\n",
       "  0.09219060886116431,\n",
       "  0.09215262175642731,\n",
       "  0.09214826624629914,\n",
       "  0.09212475602122293,\n",
       "  0.09211301485476284,\n",
       "  0.09215442044637154]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_auto_history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ba24a",
   "metadata": {},
   "source": [
    "### Display sample Results :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f91aa989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_one_row(display_img,offset,shape=(28,28)):\n",
    "    for i,test_img in enumerate(display_img):\n",
    "        plt.subplot(3,10,offset + i+ 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        test_img = np.reshape(test_img,shape)\n",
    "        plt.imshow(test_img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51c659a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 641\n"
     ]
    }
   ],
   "source": [
    "def display_result(input_img,encoded_img,decoded_img,encoded_shape=(8,4)):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    display_one_row(input_img,0,shape=(28,28,))\n",
    "    display_one_row(encoded_img,1,shape=encoded_shape)\n",
    "    display_one_row(decoded_img,shape=(28,28))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780abfac",
   "metadata": {},
   "source": [
    "### Test datasets : Take 1 Batch of Image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5661048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d33b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the input image from test data of Tensorflow datasets (mnist) & Enter them into list :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60eefa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_smaples = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfdd1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_image, image in tf_ds.as_numpy(test_dataset):\n",
    "    output_smaples = input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37bef939",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_prediction = encoder_model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b92f1d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 643\n"
     ]
    }
   ],
   "source": [
    "idxs = np.random.choice(56, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45de5866",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction_decoder = autoencoder_model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda0a600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\ipykernel_launcher.py:3: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-41-2ff5aff7bdcc>\", line 1, in <module>\n",
      "    display_result(output_smaples[idxs],encoded_prediction[idxs],final_prediction_decoder[idxs])\n",
      "  File \"<ipython-input-29-472f4dff2a62>\", line 5, in display_result\n",
      "    display_one_row(decoded_img,shape=(28,28))\n",
      "TypeError: display_one_row() missing 1 required positional argument: 'offset'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-41-2ff5aff7bdcc>\", line 1, in <module>\n",
      "    display_result(output_smaples[idxs],encoded_prediction[idxs],final_prediction_decoder[idxs])\n",
      "  File \"<ipython-input-29-472f4dff2a62>\", line 5, in display_result\n",
      "    display_one_row(decoded_img,shape=(28,28))\n",
      "TypeError: display_one_row() missing 1 required positional argument: 'offset'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-41-2ff5aff7bdcc>\", line 1, in <module>\n",
      "    display_result(output_smaples[idxs],encoded_prediction[idxs],final_prediction_decoder[idxs])\n",
      "  File \"<ipython-input-29-472f4dff2a62>\", line 5, in display_result\n",
      "    display_one_row(decoded_img,shape=(28,28))\n",
      "TypeError: display_one_row() missing 1 required positional argument: 'offset'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3282, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1211, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"D:\\SOFTWARE\\Anaconda\\envs\\gpu_tf\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 11 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_result(output_smaples[idxs],encoded_prediction[idxs],final_prediction_decoder[idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0615132d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494aa2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b2d40a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e846f6de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532cea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
